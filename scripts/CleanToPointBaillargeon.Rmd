---
title: "Untitled"
author: "Anna Talucci"
date: '2022-12-06'
output: html_document
---

# clear environment
```{r}
rm(list=ls())
```

# Overview

Adapt script form M. Loranty data_cleaning, to only clean and not aggregate data. 

Use data from csv files in Google Drive

What this script does:


# Packages

```{r}
library(tidyverse)
library(lubridate)
library(sf)
```
# Projection

WGS 84 need for gee
```{r}
wgs_proj =  "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs "
```

# Data

# vector of data files
```{r}
f <- list.files(path = "../data/GoogleDriveCsvFolder/",
                pattern = "*.csv", full.names = TRUE)
```

```{r}
f
```



## Baillargeon
```{r}
f1 <- read.csv(f[1], header = TRUE) 
```

# change organic depth range to numeric
```{r}
f1$organic_depth <- 25
```
# indicate measurements that exceed probe length
```{r}
f1$gt_probe[which(f1$thaw_depth == "100+")] <- "y"
```
# get rid of non-numeric thaw probe measurements
```{r}
f1$thaw_depth <- as.numeric(sub("100+", "100", f1$thaw_depth, fixed = TRUE))
```
# get rid of non-numeric fire year entries
```{r}
f1$fire_year <- as.numeric(sub("unburned", NA, f1$fire_year, fixed = TRUE))
```
# fix slope, which was read as logical
```{r}
f1$slope <- read.csv(f[1], header = TRUE, colClasses = "character")[,20]
```
# fix thaw_active - these are TD measurements, not ALD
```{r}
f1$thaw_active <- "T"
```

# examine unique combinations of identify information for aggregatation
```{r}
f1 %>% distinct(site_id,year,month,day,fire_id,burn_unburn)
```

```{r}
str(f1)
```

# Add date 
```{r}
f1_dates = f1 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) 

f1_dates
```

# distinct site pairs
```{r}
f1_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/balliargeon.csv')
```

```{r}
f1_dates %>% distinct(julianDate, year, date)
```

# Finish cleaning to match other datasets
```{r}
( 
  f1_clean = f1_dates %>%  
  mutate(across(c(plot_id, site_id, fire_id), as.character)) %>% 
  mutate(across(c(fire_year, organic_depth, slope, day), as.numeric)) %>% 
    mutate(across(day, ~coalesce(., 0))) %>%
  rename(lastNm = last_name, cntryId = country_code, lon=long, biome=boreal_tundra, vegCC = veg_cover_class, siteId = site_id, plotId = plot_id, fireId = fire_id, fireYr = fire_year, distur = burn_unburn, orgDpth = organic_depth, msrDepth = thaw_depth, hitRock=hit_rock, gtProbe = gt_probe, msrType = thaw_active, topoPos = topo_position, jDate = julianDate) %>%
    mutate(msrType = as.character(msrType))
)
```

# Create points shapefile

## For F1

```{r}
f1_pts = st_as_sf(f1_clean, coords = c("lon","lat"), crs = 4326, remove = FALSE)
```

### write to shapefile

```{r eval=FALSE, include=FALSE}
st_write(f1_pts, "../outputs/allPoints/Baillargeon_pts.shp", driver="ESRI Shapefile")
```