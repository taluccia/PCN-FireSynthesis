---
title: "Clean to Point & Combine"
author: "Anna Talucci"
date: "2023-09-21"
output: html_document
---

# clear environment
```{r}
rm(list=ls())
```

# Overview

Adapt script form M. Loranty data_cleaning, to only clean and not aggregate data. 

Use data from csv files in Google Drive

What this script does:


# Packages

```{r}
library(tidyverse)
library(lubridate)
library(sf)
```

# Projection

WGS 84 need for gee
```{r}
wgs_proj =  "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs "
```

# Data

# vector of data files
```{r}
f <- list.files(path = "../data/GoogleDriveCsvFolder/",
                pattern = "*.csv", full.names = TRUE)
```

```{r}
f
```


# Clean by contributor
## Baillargeon
```{r}
f1 <- read.csv(f[1], header = TRUE) 
```


```{r}
# change organic depth range to numeric
f1$organic_depth <- 25

# indicate measurements that exceed probe length
f1$gt_probe[which(f1$thaw_depth == "100+")] <- "y"

# get rid of non-numeric thaw probe measurements
f1$thaw_depth <- as.numeric(sub("100+", "100", f1$thaw_depth, fixed = TRUE))

# get rid of non-numeric fire year entries
f1$fire_year <- as.numeric(sub("unburned", NA, f1$fire_year, fixed = TRUE))

# fix slope, which was read as logical
f1$slope <- read.csv(f[1], header = TRUE, colClasses = "character")[,20]

# fix thaw_active - these are TD measurements, not ALD
f1$thaw_active <- "T"
```


```{r}
# examine unique combinations of identify information for aggregatation
f1 %>% distinct(site_id,year,month,day,fire_id,burn_unburn)
str(f1)
```

```{r}
# Add date 
(
  f1_dates = f1 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) 
)
```


```{r}
# distinct site pairs
f1_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/balliargeon.csv')
f1_dates %>% distinct(julianDate, year, date)
```

## Breen
```{r}
f2 <- read.csv(f[2], header = TRUE)
f2
```
```{r}
str(f2)
unique(f2$year)
```

```{r}
# Create single fire year
( f2_dates = f2 %>%
  mutate(fire_year = pmax(fire_year_1 , fire_year_2, fire_year_3, na.rm = TRUE)) %>%
  mutate(reburn = paste(fire_year_1 , fire_year_2, fire_year_3, sep = ', ')) %>%
    mutate(fire_id = paste(fire_id1 , fire_id2, fire_id3, sep = ', ')) %>%
  dplyr::select(last_name:day, burn_unburn:reburn, fire_id) %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) %>%
    mutate(fire_id = gsub("\\,,*", "", fire_id)) %>%
    drop_na(lat)
)
```

```{r}
# Look at distinct identifiers
f2_dates %>% distinct(site_id, plot_id, burn_unburn) %>% write.csv(., '../outputs/pairs/breen.csv')
f2_dates %>% distinct(julianDate, year, date)
```

## Buma

```{r}
# read without 17th column, which is redundant to the gt_prob column
f3 <- read.csv(f[3], header = TRUE)[,-17]
```

```{r}
# fix thaw/active column, which was read as logical
f3$thaw_active <- read.csv(f[3], header = TRUE, colClasses = "character")[,20]

# fix site_id for aggregating (see Note below from Buma)
f3$site_id <- paste(f3$site_id, sapply(strsplit(f3$plot,"_"),"[[",2), sep="_" )

#fix positive longitude values, which are in the wrong hemisphere
f3$long <- ifelse(f3$long > 0, -f3$long,f3$long)
```
NOTE---The Dalton and the Steese are larger "sites," each of which has a lot of plots in them.  But those plots do vary, so don't aggregate.  At the Dalton, there are sites with 0 (unburned), 1 (one fire, which would be 2004/2005 era), 2 fires (which would be 1970's era AND 2004 or 2005), or 3 fires (which would be 1950's, 1970's, and 2004 or 2005.  So if aggregating, what you'd want to do would be to aggregate by those treatments (0, 1, 2, or 3 fires) within the Dalton or Steese "sites."  So, sounds like you'd want to aggregate all the unburned plots at the Dalton, all the 1 burn plots at the Dalton, etc.  I would not aggregate Dalton and Steese plots together, they are functionally different sites (uplands vs. low lands, respectively).

```{r}
f3
f3 %>% distinct(site_id,year,month,day,fire_id,burn_unburn)
str(f3)
f3 %>% group_by(thaw_active) %>% count(.)
```

```{r}
( f3_dates = f3 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) 
)
```

```{r}
f3_dates %>% distinct(site_id, burn_unburn) 
f3_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/buma.csv')
f3_dates %>% distinct(julianDate, year, date)
```

## Dielman
```{r}
f4 <- read.csv(f[4], header = TRUE)
```
### fix incorrect logical columns
```{r}
f4[,c(11,18,20,21)] <- read.csv(f[4], header = TRUE, colClasses = "character")[,c(11,18,20,21)]
```

```{r}
f4 %>% distinct(site_id,year,month,day,fire_id,burn_unburn)
```

```{r}
str(f4)
```

```{r}
unique(f4$site_id)
```

```{r}
f4 %>% group_by(thaw_active, site_id) %>% count(.)
f4 %>% filter(thaw_active == "T")
f4 %>% filter(thaw_active == "A")
```

```{r}
(
  f4_dates = f4 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) 
)
```

```{r}
f4_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/dielman.csv')
f4_dates %>% distinct(julianDate, year, date)
```

## Douglas
```{r}
f5 <- read.csv(f[5], header = TRUE)
f5
```
```{r}
str(f5)
```

```{r}
## fix incorrect logical columns
f5$slope <- read.csv(f[5], header = TRUE, colClasses = "character")[,20]
```

```{r}
f5_dates = f5 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) %>%
  dplyr::select(-notes) 

f5_dates
```


```{r}
f5_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/douglas.csv')
f5_dates %>% distinct(julianDate, year, date)
```


## Frost
```{r}
f6 <- read.csv(f[6], header = TRUE)
f6
```
```{r}
str(f6)
```

```{r}
f6$thaw_active <- read.csv(f[6], header = TRUE, colClasses = "character")[,19]
```

```{r}
unique(f6$site_id)
f6 %>% group_by(thaw_active, site_id) %>% count(.)
f6 %>% filter(thaw_active == "T")
```

```{r}
( 
f6_dates = f6 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) 
)
```


```{r}
f6_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/frost.csv')
f6_dates %>% distinct(julianDate, year, date)
```

## Gaglioti

```{r}
f7 <- read.csv(f[7], header = TRUE)
f7
```

```{r}
# set gt_probe
f7$gt_probe <- "n"

# organic depth is missing, but set to NA
f7$organic_depth <- as.numeric(f7$organic_depth)
```

```{r}
str(f7)
```

```{r}
(
  f7_dates = f7 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) %>%
  dplyr::select(-Notes) 
)
```

```{r}
f7_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/gaglioti.csv')
f7_dates %>% distinct(julianDate, year, date)
```

## Holloway
```{r}
f8 <- read.csv(f[8], header = TRUE) 
```

```{r}
# View data
glimpse(f8)
```

```{r}
# check thaw_active and slope
unique(f8$thaw_active)
unique(f8$slope)
```

```{r}
# Check gt_probe yes
gtProbeYes = filter(f8, gt_probe=="y")
unique(gtProbeYes$thaw_depth)
```

```{r}
# Fixes 
f8 = f8 %>%
     mutate(thaw_active=replace(thaw_active, thaw_active==TRUE, 'thaw')) %>% # switch true to thaw
     as.data.frame() %>%
  mutate(slope=replace(slope, slope==FALSE, 'flat')) %>% # switch false to flat
     as.data.frame() %>%
  mutate(gt_probe=replace(gt_probe, thaw_depth==87, "n")) %>%
     as.data.frame() %>%
  mutate(gt_probe=replace(gt_probe, thaw_depth %in% c("110+", "125+", "120+", "180+", "195+"), "y")) %>%
     as.data.frame() %>%
  mutate(thaw_depth = gsub("\\+","", thaw_depth)) %>%
  mutate(thaw_depth = as.numeric(thaw_depth))
```

```{r}
f8
# examine unique combinations of identify information for aggregatation
f8 %>% distinct(site_id,year,month,day,fire_id,burn_unburn)
str(f8)
```

```{r}
(
  f8_dates = f8 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) 
)
```

```{r}
f8_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn, pairUnb) %>% write.csv(., '../outputs/pairs/holloway.csv')
f8_dates %>% distinct(julianDate, year, date)
```

## Manies
```{r}
f9 <- read.csv(f[9], header = TRUE)
f9
```
```{r}
str(f9)
```


```{r}
# Fixes 
f9 = f9 %>%
   mutate(thaw_active=replace(thaw_active, thaw_active==TRUE, 'thaw')) %>% # switch true to thaw
     as.data.frame() %>%
  mutate(slope=replace(slope, slope==FALSE, 'flat')) %>% # switch false to flat
     as.data.frame() %>%
  mutate(organic_depth = (na.strings = "unk")) %>%
     as.data.frame() 
```

```{r}
f9_dates = f9 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) %>%
  dplyr::select(-notes)

f9_dates
```

```{r}
f9_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/manies.csv')
f9_dates %>% distinct(site_id, thaw_active, julianDate, year, date)
```

## Natali
```{r}
f10 <- read.csv(f[10], header = TRUE)
f10
```


```{r}
# fix incorrect logical columns
# organic depth is missing, but set to NA
f10$organic_depth <- as.numeric(f10$organic_depth)

# fix incorrect logical columns
f10[,c(20:22)] <- read.csv(f[10], header = TRUE, colClasses = "character")[,c(20:22)]

# remove characters from thaw depth and convert to numeric
f10$thaw_depth <- gsub("+", "", f10$thaw_depth, fixed = TRUE)
f10$thaw_depth <- as.numeric(gsub(">", "", f10$thaw_depth, fixed = TRUE))
f10$long = as.numeric(gsub(",","",f10$long))
#fix positive longitude values, which are in the wrong hemisphere
f10$long <- ifelse(f10$long > 0, -f3$long,f3$long)
```

```{r}
str(f10)
```

```{r}
(
  f10_dates = f10 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) 
)
```

```{r}
unique(f10_dates$site_id)
f10_dates %>% group_by(thaw_active, site_id) %>% count(.)
f10_dates %>% filter(thaw_active == "T")
f10_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/natali.csv')
f10_dates %>% filter(site_id =="YKD")
f10_dates %>% distinct(julianDate, year, date)
f10_dates %>% filter_all(any_vars(is.na(.))) 
```

## O'Donnell
```{r}
f11 <- read.csv(f[11], header = TRUE)
f11
```
```{r}
str(f11)
```

```{r}
# fix incorrect logical columns
f11$organic_depth <- as.numeric(gsub(">", "",f11$organic_depth))

f11$thaw_depth <- as.numeric(gsub(">", "",f11$thaw_depth))

f11 %>% distinct(site_id,year,month,day,fire_id,burn_unburn)
```

```{r}
( 
  f11_dates = f11 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date))
)
```

```{r}
f11 %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/odonnell.csv')
f11_dates %>% distinct(julianDate, year, date)
f11_dates %>% distinct(site_id, thaw_active, julianDate, year, date)
```

## Olefeldt
```{r}
f12 <- read.csv(f[12], header = TRUE)
f12
```

```{r}
# fix incorrect logical columns
f12$slope <- read.csv(f[12], header = TRUE, colClasses = "character")[,20]

# remove non-numeric characters from numeric vars
# note we're loosing info on where Organic Layer Thickness is in excess of the entered value
f12$organic_depth <- as.numeric(gsub(">", "",f12$organic_depth))

f12 %>% distinct(site_id,year,month,day,fire_id,burn_unburn)
```

```{r}
str(f12)
```

```{r}
(
  f12_dates = f12 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) #%>%
  #dplyr::select(-fire_id)
)
```

```{r}
f12_dates %>% filter_all(any_vars(is.na(.))) 
f12_dates %>% distinct(site_id, plot_id, burn_unburn) %>% write.csv(., '../outputs/pairs/olefeldt.csv')
f12_dates %>% distinct(julianDate, year, date)
```

## Paulson
```{r}
f13 <- read.csv(f[13], header = TRUE)
f13
```

```{r}
# fix incorrect logical columns
f13$thaw_active <- read.csv(f[13], header = TRUE, colClasses = "character")[,19]

f13 %>% distinct(site_id,year,month,day,fire_id,burn_unburn)
```

```{r}
str(f13)
``` 

```{r}
( 
  f13_dates = f13 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) %>%
  dplyr::select(-notes) 
)
```

```{r}
f13_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/paulson.csv')
f13_dates %>% distinct(julianDate, year, date)
```

## Rocha
```{r}
f14 <- read.csv(f[14], header = TRUE)
f14
```

```{r}
# fix incorrect logical columns
f14$slope <- read.csv(f[14], header = TRUE, colClasses = "character")[,20]
# organic depth is missing, but set to NA
f14$organic_depth <- as.numeric(f14$organic_depth)
# convert thaw depth to numeric - blank cells have a period, and will be converted to NA
f14$thaw_depth <- as.numeric(f14$thaw_depth)
```

```{r}
str(f14)
```

```{r}
(
  f14_dates = f14 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) %>%
  dplyr::select(-notes)
)
```

```{r}
f14_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/rocha.csv')
f14_dates %>% distinct(julianDate, year, date)
```

## Sizov
```{r}
f15 <- read.csv(f[15], header = TRUE)
f15
```
```{r}
str(f15)
```

```{r}
(
  f15_dates = f15 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) %>%
  dplyr::select(-notes)
)
```

```{r}
f15_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/sizov.csv')
f15_dates %>% distinct(julianDate, year, date)
```

## Veraverbeke
```{r}
f16 <- read.csv(f[16], header = TRUE)
f16
```
```{r}
str(f16)
```

```{r}
# fix incorrect logical columns
f16$thaw_active <- read.csv(f[16], header = TRUE, colClasses = "character")[,19]
```

```{r}
(
  f16_dates = f16 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) %>%
  drop_na((lat))
)
```

```{r}
f16_dates %>% distinct(site_id, plot_id, fire_id, burn_unburn) %>% write.csv(., '../outputs/pairs/veraverbeke.csv')
f16_dates %>% distinct(julianDate, year, date)
```


# Match Data structure across dataframes 

# Function to clean
```{r}
clean <- function(df){ df %>%
  mutate(across(c(plot_id, site_id, fire_id), as.character)) %>% 
  mutate(across(c(fire_year, organic_depth, slope, day), as.numeric)) %>% 
    mutate(across(c(fire_year, organic_depth, slope, day), ~replace(., is.na(.), -9999))) %>%
    mutate(across(day, ~coalesce(., 0))) %>%
  rename(lastNm = last_name, cntryId = country_code, lon=long, biome=boreal_tundra, vegCC = veg_cover_class, siteId = site_id, plotId = plot_id, fireId = fire_id, fireYr = fire_year, distur = burn_unburn, orgDpth = organic_depth, msrDepth = thaw_depth, hitRock=hit_rock, gtProbe = gt_probe, msrType = thaw_active, topoPos = topo_position, jDate = julianDate) %>%
    mutate(msrType = as.character(msrType))
}

```

## Apply functions
```{r}
f1_clean = clean(f1_dates)
f2_clean = clean(f2_dates)
f3_clean = clean(f3_dates)
f4_clean = clean(f4_dates)
f5_clean = clean(f5_dates)
f6_clean = clean(f6_dates)
f7_clean = clean(f7_dates)
f8_clean = clean(f8_dates)
f9_clean = clean(f9_dates)
f10_clean = clean(f10_dates)
f11_clean = clean(f11_dates)
f12_clean = clean(f12_dates)
f13_clean = clean(f13_dates)
f14_clean = clean(f14_dates)
f16_clean = clean(f16_dates)
```

```{r}
glimpse(f10_clean)
```


# Create points shapefile
## Function to make points
```{r}
df_to_sf <- function(x){
  st_as_sf(x, coords = c("lon","lat"), crs = 4326, remove = FALSE)
}
```
## Apply function
```{r}
f1_pts = df_to_sf(f1_clean)
f2_pts = df_to_sf(f2_clean)
f3_pts = df_to_sf(f3_clean)
f4_pts = df_to_sf(f4_clean)
f5_pts = df_to_sf(f5_clean)
f6_pts = df_to_sf(f6_clean)
f7_pts = df_to_sf(f7_clean)
f8_pts = df_to_sf(f8_clean)
f9_pts = df_to_sf(f9_clean)
f10_pts = df_to_sf(f10_clean)
f11_pts = df_to_sf(f11_clean)
f12_pts = df_to_sf(f12_clean)
f13_pts = df_to_sf(f13_clean)
f14_pts = df_to_sf(f14_clean)
f15_pts = df_to_sf(f15_clean)
f16_pts = df_to_sf(f16_clean)
```

## write to shapefile

```{r eval=FALSE, include=FALSE}
st_write(f1_pts, "../outputs/allPoints/Baillargeon_pts.shp", driver="ESRI Shapefile")
st_write(f2_pts, "../outputs/allPoints/Breen_pts.shp", driver="ESRI Shapefile")
st_write(f3_pts, "../outputs/allPoints/Buma_pts.shp", driver="ESRI Shapefile")
st_write(f4_pts, "../outputs/allPoints/Dielman_pts.shp", driver="ESRI Shapefile")
st_write(f5_pts, "../outputs/allPoints/Douglas_pts.shp", driver="ESRI Shapefile")
st_write(f6_pts, "../outputs/allPoints/Frost_pts.shp", driver="ESRI Shapefile")
st_write(f7_pts, "../outputs/allPoints/Gaglioti_pts.shp", driver="ESRI Shapefile")
st_write(f8_pts, "../outputs/allPoints/Holloway_pts.shp", driver="ESRI Shapefile")
st_write(f9_pts, "../outputs/allPoints/Manies_pts.shp", driver="ESRI Shapefile")
st_write(f10_pts, "../outputs/allPoints/Natali_pts.shp", driver="ESRI Shapefile")
st_write(f11_pts, "../outputs/allPoints/ODonnell_pts.shp", driver="ESRI Shapefile")
st_write(f12_pts, "../outputs/allPoints/Olefeldt_pts.shp", driver="ESRI Shapefile")
st_write(f13_pts, "../outputs/allPoints/Paulson_pts.shp", driver="ESRI Shapefile")
st_write(f14_pts, "../outputs/allPoints/Rocha_pts.shp", driver="ESRI Shapefile")
st_write(f15_pts, "../outputs/allPoints/Sizov_pts.shp", driver="ESRI Shapefile")
st_write(f16_pts, "../outputs/allPoints/Veraverbeke_pts.shp", driver="ESRI Shapefile")
```