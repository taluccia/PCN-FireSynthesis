---
title: "Natali Clean to Point"
author: "Anna Talucci"
date: '2022-12-11'
output: html_document
---




# clear environment
```{r}
rm(list=ls())
```

# Overview
**MISSING SOME DAY OF MONTH but it does not matter because the thaw depth measures (n=732 from site_id=YKD) all have dates which are needed to standarize** **ERROR WHEN CREATING POINTS**
Adapt script form M. Loranty data_cleaning, to only clean and not aggregate data. Split data by active and thaw, add julian date for thaw, create point shapefile for each active and thaw.

Use data from csv files in Google Drive

What this script does:


# Packages

```{r}
library(tidyverse)
library(lubridate)
library(sf)
```
# Projection

WGS 84 need for gee
```{r}
wgs_proj =  "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs "
```

# Data

# vector of data files
```{r}
f <- list.files(path = "../data/GoogleDriveCsvFolder/",
                pattern = "*.csv", full.names = TRUE)
```

```{r}
f
```



## Natali
```{r}
f9 <- read.csv(f[9], header = TRUE)
f9
```

# fix incorrect logical columns
```{r}
# organic depth is missing, but set to NA
f9$organic_depth <- as.numeric(f9$organic_depth)

# fix incorrect logical columns
f9[,c(20:22)] <- read.csv(f[9], header = TRUE, colClasses = "character")[,c(20:22)]

# remove characters from thaw depth and convert to numeric
f9$thaw_depth <- gsub("+", "", f9$thaw_depth, fixed = TRUE)
f9$thaw_depth <- as.numeric(gsub(">", "", f9$thaw_depth, fixed = TRUE))
f9$long = as.numeric(gsub(",","",f9$long))
```

```{r}
str(f9)
```

```{r}
f9_dates = f9 %>%
  mutate(date = as.Date(with(., paste(year, month, day,sep="-")), "%Y-%m-%d")) %>%
  mutate(julianDate = yday(date)) 

f9_dates
```
%>%
  drop_na(day) %>%
  drop_na(thaw_depth) %>%
  drop_na(lat) %>%
  drop_na(long) %>%
  dplyr::select(-fire_id, -organic_depth, -slope, -topo_position, -surface_water, -fire_year) 



```{r}
unique(f9_dates$site_id)
```
```{r}
f9_dates %>% group_by(thaw_active, site_id) %>% count(.)
```
There are 732 measurements as thaw depth from site_id YKD

```{r}
f9_dates %>% filter(thaw_active == "T")
```
```{r}
f9_dates %>% filter(site_id =="YKD")
```

```{r}
f9_dates %>% distinct(julianDate, year, date)
```
```{r}
f9_dates %>% filter_all(any_vars(is.na(.))) 
```

# Split by active & thaw
```{r}
f9_thaw = f9_dates %>% 
  filter(thaw_active == "T") %>%
  drop_na(long) %>%
  drop_na(lat)

f9_active = f9_dates %>% 
  filter(thaw_active == "A") %>%
  drop_na(long) %>%
  drop_na(lat)
```

```{r}
f9_active %>% 
  filter(is.na(long))

f9_active %>% 
  filter(is.na(lat))
```
# Create points shapefile

## For F9
sf::st_as_sf(dd, coords = c("x","y"))
```{r}
f9_thaw_pts = st_as_sf(f9_thaw, coords = c("long","lat"), crs = 4326, remove = FALSE)
f9_active_pts = st_as_sf(f9_active, coords = c("long","lat"), crs = 4326, remove = FALSE)
```


### write to shapefile
```{r}
st_write(f9_thaw_pts, "../outputs/ThawPoints/Natali_thaw_pts.shp", driver="ESRI Shapefile")
st_write(f9_active_pts, "../outputs/ActivePoints/Natali_active_pts.shp", driver="ESRI Shapefile")
```